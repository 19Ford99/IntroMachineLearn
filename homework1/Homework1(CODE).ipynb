{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4083be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# printing numbers in array's\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 & 2\n",
    "\n",
    "def compute_loss(X,y,theta):\n",
    "#    **** Computes the loss function for linear regression ****\n",
    "    h = X.dot(theta) # h = predictions\n",
    "    errors = np.subtract(h,y)\n",
    "    sqrErrors = np.square(errors)\n",
    "    J = 1/(2*m) * np.sum(sqrErrors)\n",
    "    return J\n",
    "\n",
    "def gradient_descent(X_train,X_test,Y_train,Y_test,theta,alpha,iterations):\n",
    "#    **** Computes the Gradient Descent for linear regression ****\n",
    "    loss_history_train = np.zeros(iterations)\n",
    "    loss_history_test = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        h = X_train.dot(theta)\n",
    "        errors = np.subtract(h,Y_train)\n",
    "        sum_delta = (alpha/m) * X_train.transpose().dot(errors);\n",
    "        theta = theta - sum_delta;\n",
    "        loss_history_train[i] = compute_loss(X_train,Y_train,theta)\n",
    "        loss_history_test[i] = compute_loss(X_test,Y_test,theta)\n",
    "    return loss_history_train, loss_history_test, theta\n",
    "\n",
    "def binary_map(x):\n",
    "#    **** Computes the inputs for 1(yes) or 0(no) ****\n",
    "    return x.map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1.a\n",
    "# Code that predicts housing price based on input variables\n",
    "# Inputs: area, bedrooms, bathrooms, stories, parking\n",
    "\n",
    "# Reads csv file and sets it to the variable housing\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\", usecols = [\"price\",\"area\",\"bedrooms\",\"bathrooms\",\"stories\",\"parking\"]))\n",
    "housing = housing.to_numpy()\n",
    "\n",
    "# Splits the training/validation set\n",
    "np.random.seed(0) \n",
    "train, test = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "\n",
    "m = len(train) # Number of values in dataset\n",
    "\n",
    "# Spliting the inputs and output\n",
    "Y_train = train[:,0]\n",
    "X_train = train[:,1:]\n",
    "Y_test = test[:,0]\n",
    "X_test = test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train and X_test\n",
    "X0 = np.ones((len(X_train),1))\n",
    "X_train = np.hstack((X0, X_train))\n",
    "X0 = np.ones((len(X_test),1))\n",
    "X_test = np.hstack((X0, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ce3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(6)\n",
    "alpha = 1e-10\n",
    "iterations = 1000\n",
    "loss_history_train, loss_history_test, theta = gradient_descent(X_train,X_test,Y_train,Y_test,theta,alpha,iterations)\n",
    "print(\"Theta for X= \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc346ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Loss vs Iterations\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train[0:len(loss_history_train)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test[0:len(loss_history_test)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a053fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c204d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1.b\n",
    "# Code that predicts housing price based on input variables\n",
    "# Inputs: area, bedrooms, bathrooms, stories, mainroad, guestroom, basement, hotwaterheating, airconditioning, parking, prefarea\n",
    "\n",
    "# Reads csv file and sets it to the variable housing\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\", usecols = [\"price\",\"area\",\"bedrooms\",\"bathrooms\",\"stories\",\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"parking\",\"prefarea\"]))\n",
    "binarylist = [\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"prefarea\",]\n",
    "housing[binarylist] = housing[binarylist].apply(binary_map)\n",
    "housing = housing.to_numpy()\n",
    "\n",
    "# Splits the training/validation set\n",
    "np.random.seed(0) \n",
    "train, test = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "\n",
    "m = len(train) # Number of values in dataset\n",
    "\n",
    "# Spliting the inputs and output\n",
    "Y_train = train[:,0]\n",
    "X_train = train[:,1:]\n",
    "Y_test = test[:,0]\n",
    "X_test = test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train and X_test\n",
    "X0 = np.ones((len(X_train),1))\n",
    "X_train = np.hstack((X0, X_train))\n",
    "X0 = np.ones((len(X_test),1))\n",
    "X_test = np.hstack((X0, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cf26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(12)\n",
    "alpha = 1e-10\n",
    "iterations = 1000\n",
    "loss_history_train, loss_history_test, theta = gradient_descent(X_train,X_test,Y_train,Y_test,theta,alpha,iterations)\n",
    "print(\"Theta for X=: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Loss vs Iterations\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train[0:len(loss_history_train)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test[0:len(loss_history_test)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963eeac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2.a\n",
    "# Repeat 1.a\n",
    "\n",
    "# Reads csv file and sets it to the variable housing\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\", usecols = [\"price\",\"area\",\"bedrooms\",\"bathrooms\",\"stories\",\"parking\"]))\n",
    "housing = housing.to_numpy()\n",
    "\n",
    "# Splits the training/validation set\n",
    "np.random.seed(0) \n",
    "train, test = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "\n",
    "m = len(train) # Number of values in dataset\n",
    "\n",
    "# Feature Scaling\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "std_train = scaler.fit_transform(train) \n",
    "std_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "norm_train = scaler.fit_transform(train)\n",
    "norm_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization: Spliting the inputs and output\n",
    "Y_train_norm = norm_train[:,0]\n",
    "X_train_norm = norm_train[:,1:]\n",
    "Y_test_norm = norm_test[:,0]\n",
    "X_test_norm = norm_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_norm),1))\n",
    "X_train_norm = np.hstack((X0, X_train_norm))\n",
    "X0 = np.ones((len(X_test_norm),1))\n",
    "X_test_norm = np.hstack((X0, X_test_norm))\n",
    "\n",
    "\n",
    "# Standardization: Spliting the inputs and output\n",
    "Y_train_std = std_train[:,0]\n",
    "X_train_std = std_train[:,1:]\n",
    "Y_test_std = std_test[:,0]\n",
    "X_test_std = std_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_std),1))\n",
    "X_train_std = np.hstack((X0, X_train_std))\n",
    "X0 = np.ones((len(X_test_std),1))\n",
    "X_test_std = np.hstack((X0, X_test_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd5ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(6)\n",
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "loss_history_train_norm, loss_history_test_norm, theta = gradient_descent(X_train_norm,X_test_norm,Y_train_norm,Y_test_norm,theta,alpha,iterations)\n",
    "print(\"Normalization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b07e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(6)\n",
    "alpha = 0.01\n",
    "iterations = 300\n",
    "loss_history_train_std, loss_history_test_std, theta = gradient_descent(X_train_std,X_test_std,Y_train_std,Y_test_std,theta,alpha,iterations)\n",
    "print(\"Standardization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Loss vs Iterations\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_norm[0:len(loss_history_train_norm)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_norm[0:len(loss_history_test_norm)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_std[0:len(loss_history_train_std)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_std[0:len(loss_history_test_std)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9c255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2.b\n",
    "# Repeat 1.b\n",
    "\n",
    "# Reads csv file and sets it to the variable housing\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\", usecols = [\"price\",\"area\",\"bedrooms\",\"bathrooms\",\"stories\",\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"parking\",\"prefarea\"]))\n",
    "binarylist = [\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"prefarea\",]\n",
    "housing[binarylist] = housing[binarylist].apply(binary_map)\n",
    "\n",
    "# Splits the training/validation set\n",
    "np.random.seed(0) \n",
    "train, test = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "\n",
    "m = len(train) # Number of values in dataset\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "std_train = scaler.fit_transform(train) \n",
    "std_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "norm_train = scaler.fit_transform(train)\n",
    "norm_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization: Spliting the inputs and output\n",
    "Y_train_norm = norm_train[:,0]\n",
    "X_train_norm = norm_train[:,1:]\n",
    "Y_test_norm = norm_test[:,0]\n",
    "X_test_norm = norm_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_norm),1))\n",
    "X_train_norm = np.hstack((X0, X_train_norm))\n",
    "X0 = np.ones((len(X_test_norm),1))\n",
    "X_test_norm = np.hstack((X0, X_test_norm))\n",
    "\n",
    "\n",
    "# Standardization: Spliting the inputs and output\n",
    "Y_train_std = std_train[:,0]\n",
    "X_train_std = std_train[:,1:]\n",
    "Y_test_std = std_test[:,0]\n",
    "X_test_std = std_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_std),1))\n",
    "X_train_std = np.hstack((X0, X_train_std))\n",
    "X0 = np.ones((len(X_test_std),1))\n",
    "X_test_std = np.hstack((X0, X_test_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(12)\n",
    "alpha = 0.01\n",
    "iterations = 200\n",
    "loss_history_train_norm, loss_history_test_norm, theta = gradient_descent(X_train_norm,X_test_norm,Y_train_norm,Y_test_norm,theta,alpha,iterations)\n",
    "print(\"Normalization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(12)\n",
    "alpha = 0.01\n",
    "iterations = 200\n",
    "loss_history_train_std, loss_history_test_std, theta = gradient_descent(X_train_std,X_test_std,Y_train_std,Y_test_std,theta,alpha,iterations)\n",
    "print(\"Standardization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294fe87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the Loss vs Iterations\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_norm[0:len(loss_history_train_norm)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_norm[0:len(loss_history_test_norm)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_std[0:len(loss_history_train_std)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_std[0:len(loss_history_test_std)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca46cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3\n",
    "\n",
    "def compute_loss_train(X,y,theta):\n",
    "#    **** Computes the loss function for linear regression with regularization ****   \n",
    "    h = X.dot(theta)\n",
    "    errors = np.subtract(h,y)\n",
    "    sqrErrors = np.square(errors)\n",
    "    reg = np.square(theta[1:])\n",
    "    reg = np.insert(reg, 0, theta[:1], axis=0)\n",
    "    J = 1/(2*m) * ((np.sum(sqrErrors)) + (np.sum(reg)))\n",
    "    return J\n",
    "\n",
    "def compute_loss_test(X,y,theta):\n",
    "#    **** Computes the loss function for linear regression with regularization****\n",
    "    h = X.dot(theta)\n",
    "    errors = np.subtract(h,y)\n",
    "    sqrErrors = np.square(errors)\n",
    "    J = 1/(2*m) * (np.sum(sqrErrors))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.a\n",
    "# Repeat problem 2.a\n",
    "\n",
    "# Reads csv file and sets it to the variable housing\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\", usecols = [\"price\",\"area\",\"bedrooms\",\"bathrooms\",\"stories\",\"parking\"]))\n",
    "\n",
    "# Splits the training/validation set\n",
    "np.random.seed(0) \n",
    "train, test = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "\n",
    "m = len(train) # Number of values in dataset\n",
    "\n",
    "# Feature Scaling\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "std_train = scaler.fit_transform(train) \n",
    "std_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "norm_train = scaler.fit_transform(train)\n",
    "norm_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization: Spliting the inputs and output\n",
    "Y_train_norm = norm_train[:,0]\n",
    "X_train_norm = norm_train[:,1:]\n",
    "Y_test_norm = norm_test[:,0]\n",
    "X_test_norm = norm_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_norm),1))\n",
    "X_train_norm = np.hstack((X0, X_train_norm))\n",
    "X0 = np.ones((len(X_test_norm),1))\n",
    "X_test_norm = np.hstack((X0, X_test_norm))\n",
    "\n",
    "# Standardization: Spliting the inputs and output\n",
    "Y_train_std = std_train[:,0]\n",
    "X_train_std = std_train[:,1:]\n",
    "Y_test_std = std_test[:,0]\n",
    "X_test_std = std_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_std),1))\n",
    "X_train_std = np.hstack((X0, X_train_std))\n",
    "X0 = np.ones((len(X_test_std),1))\n",
    "X_test_std = np.hstack((X0, X_test_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ff6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(6)\n",
    "alpha = 0.01\n",
    "iterations = 500\n",
    "loss_history_train_norm, loss_history_test_norm, theta = gradient_descent(X_train_norm,X_test_norm,Y_train_norm,Y_test_norm,theta,alpha,iterations)\n",
    "print(\"Normalization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(6)\n",
    "alpha = 0.01\n",
    "iterations = 200\n",
    "loss_history_train_std, loss_history_test_std, theta = gradient_descent(X_train_std,X_test_std,Y_train_std,Y_test_std,theta,alpha,iterations)\n",
    "print(\"Standardization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Loss vs Iterations\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_norm[0:len(loss_history_train_norm)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_norm[0:len(loss_history_test_norm)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_std[0:len(loss_history_train_std)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_std[0:len(loss_history_test_std)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ca815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3.b\n",
    "# Repeat problem 2.b \n",
    "\n",
    "# Reads csv file and sets it to the variable housing\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\", usecols = [\"price\",\"area\",\"bedrooms\",\"bathrooms\",\"stories\",\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"parking\",\"prefarea\"]))\n",
    "binarylist = [\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"prefarea\",]\n",
    "housing[binarylist] = housing[binarylist].apply(binary_map)\n",
    "\n",
    "# Splits the training/validation set\n",
    "np.random.seed(0) \n",
    "train, test = train_test_split(housing, train_size = 0.8, test_size = 0.2, random_state = 42)\n",
    "\n",
    "m = len(train) # Number of values in dataset\n",
    "\n",
    "# Feature Scaling\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "std_train = scaler.fit_transform(train) \n",
    "std_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "norm_train = scaler.fit_transform(train)\n",
    "norm_test = scaler.fit_transform(test)\n",
    "\n",
    "# Normalization: Spliting the inputs and output\n",
    "Y_train_norm = norm_train[:,0]\n",
    "X_train_norm = norm_train[:,1:]\n",
    "Y_test_norm = norm_test[:,0]\n",
    "X_test_norm = norm_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_norm),1))\n",
    "X_train_norm = np.hstack((X0, X_train_norm))\n",
    "X0 = np.ones((len(X_test_norm),1))\n",
    "X_test_norm = np.hstack((X0, X_test_norm))\n",
    "\n",
    "# Standardization: Spliting the inputs and output\n",
    "Y_train_std = std_train[:,0]\n",
    "X_train_std = std_train[:,1:]\n",
    "Y_test_std = std_test[:,0]\n",
    "X_test_std = std_test[:,1:]\n",
    "\n",
    "# Adding X0 to X_train_norm and X_test_norm\n",
    "X0 = np.ones((len(X_train_std),1))\n",
    "X_train_std = np.hstack((X0, X_train_std))\n",
    "X0 = np.ones((len(X_test_std),1))\n",
    "X_test_std = np.hstack((X0, X_test_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567eaab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(12)\n",
    "alpha = 0.01\n",
    "iterations = 200\n",
    "loss_history_train_norm, loss_history_test_norm, theta = gradient_descent(X_train_norm,X_test_norm,Y_train_norm,Y_test_norm,theta,alpha,iterations)\n",
    "print(\"Normalization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b660d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating theta\n",
    "theta = np.zeros(12)\n",
    "alpha = 0.01\n",
    "iterations = 200\n",
    "loss_history_train_std, loss_history_test_std, theta = gradient_descent(X_train_std,X_test_std,Y_train_std,Y_test_std,theta,alpha,iterations)\n",
    "print(\"Standardization: Theta for X: \", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3021a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Loss vs Iterations\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_norm[0:len(loss_history_train_norm)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_norm[0:len(loss_history_test_norm)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.plot(loss_history_train_std[0:len(loss_history_train_std)], color='blue', label=\"Training Loss\")\n",
    "plt.plot(loss_history_test_std[0:len(loss_history_test_std)], color='red', label=\"Validation Loss\")\n",
    "plt.grid(linestyle='-.', linewidth='1')\n",
    "plt.xlabel(\"Number of Iterations\", color='red')\n",
    "plt.ylabel(\"J\", color='red')\n",
    "plt.title(\"Training and Validation Losses vs Iteration\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
