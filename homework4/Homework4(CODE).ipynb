{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a881ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and cleaning the data\n",
    "breast = load_breast_cancer()\n",
    "breast_data = breast.data\n",
    "breast_input = pd.DataFrame(breast_data)\n",
    "breast_labels = breast.target\n",
    "labels = np.reshape(breast_labels,(569,1))\n",
    "final_breast_data = np.concatenate([breast_data,labels],axis=1)\n",
    "final_breast_data.shape\n",
    "breast_dataset = pd.DataFrame(final_breast_data)\n",
    "features = breast.feature_names\n",
    "features_labels = np.append(features,'label')\n",
    "breast_dataset.columns = features_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ba353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = breast_dataset.iloc[:,:30].values \n",
    "Y = breast_dataset.iloc[:, 30].values \n",
    "\n",
    "# Scaling the features\n",
    "sc_X = StandardScaler() \n",
    "std_X = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788f002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "# Feature extraction using PCA\n",
    "# Scaling the features\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "# Using a linear kernal\n",
    "for i in range(30):\n",
    "    print(i+1)\n",
    "    pca = PCA(n_components=i+1)\n",
    "    principalComponents = pca.fit_transform(std_X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "    # Creating the SVM model and fitting it\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y, train_size = 0.80, test_size = 0.20, random_state=0)\n",
    "    model = SVC(kernel='linear', C=1E6) \n",
    "    model.fit(X_train, Y_train) \n",
    "    # Creating predictions with the test data\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy.append(metrics.accuracy_score(Y_test, Y_pred))\n",
    "    precision.append(metrics.precision_score(Y_test, Y_pred))\n",
    "    recall.append(metrics.recall_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f61860b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the accuracy, precision, and recall against the iterations\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.plot(range(30),accuracy, label = 'Accuracy', color = 'blue')\n",
    "plt.plot(range(30),precision, label = 'Precision', color = 'red')\n",
    "plt.plot(range(30),recall, label = 'Recall',  color = 'green')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Figure 1: (Accuracy/Precision/Recall) vs the Iterations for Linear Kernel')\n",
    "plt.xticks(range(30))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a poly kernal\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "for i in range(30):\n",
    "    pca = PCA(n_components=i+1)\n",
    "    principalComponents = pca.fit_transform(std_X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "    # Creating the SVM model and fitting it\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y, train_size = 0.80, test_size = 0.20, random_state=0)\n",
    "    model = SVC(kernel='poly', C=1E6) \n",
    "    model.fit(X_train, Y_train) \n",
    "    # Creating predictions with the test data\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy.append(metrics.accuracy_score(Y_test, Y_pred))\n",
    "    precision.append(metrics.precision_score(Y_test, Y_pred))\n",
    "    recall.append(metrics.recall_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy, precision, and recall against the iterations\n",
    "plt.figure()\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.plot(range(30),accuracy, label = 'Accuracy', color = 'blue')\n",
    "plt.plot(range(30),precision, label = 'Precision', color = 'red')\n",
    "plt.plot(range(30),recall, label = 'Recall',  color = 'green')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Figure 2: (Accuracy/Precision/Recall) vs the Iterations for Poly Kernel')\n",
    "plt.xticks(range(30))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an rbf kernal\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "for i in range(30):\n",
    "    pca = PCA(n_components=i+1)\n",
    "    principalComponents = pca.fit_transform(std_X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "    # Creating the SVM model and fitting it\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y, train_size = 0.80, test_size = 0.20, random_state=0)\n",
    "    model = SVC(kernel='rbf', C=1E6) \n",
    "    model.fit(X_train, Y_train) \n",
    "    # Creating predictions with the test data\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy.append(metrics.accuracy_score(Y_test, Y_pred))\n",
    "    precision.append(metrics.precision_score(Y_test, Y_pred))\n",
    "    recall.append(metrics.recall_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the accuracy, precision, and recall against the iterations\n",
    "plt.figure()\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.plot(range(30),accuracy, label = 'Accuracy', color = 'blue')\n",
    "plt.plot(range(30),precision, label = 'Precision', color = 'red')\n",
    "plt.plot(range(30),recall, label = 'Recall',  color = 'green')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Figure 3: (Accuracy/Precision/Recall) vs the Iterations for RBF Kernel')\n",
    "plt.xticks(range(30))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38017929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.svm import SVR\n",
    "# Importing the dataset\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\"))\n",
    "housing = pd.DataFrame(pd.read_csv(\"Housing.csv\", usecols = [\"price\",\"area\",\"bedrooms\",\"bathrooms\",\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"prefarea\",\"stories\",\"parking\"]))\n",
    "\n",
    "# Maping the yes/no inputs to 1 and 0\n",
    "def binary_map(x):\n",
    "    return x.map({'yes': 1, \"no\": 0})\n",
    "\n",
    "binarylist = [\"mainroad\",\"guestroom\",\"basement\",\"hotwaterheating\",\"airconditioning\",\"prefarea\",]\n",
    "housing[binarylist] = housing[binarylist].apply(binary_map)\n",
    "housing = housing.to_numpy()\n",
    "\n",
    "Y = housing[:,0]\n",
    "X = housing[:,1:]\n",
    "\n",
    "# Scaling the features\n",
    "sc_X = StandardScaler() \n",
    "std_X = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7067352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using PCA\n",
    "# Scaling the features\n",
    "mean_squared_error = []\n",
    "\n",
    "# Using a linear kernal\n",
    "for i in range(11):\n",
    "    pca = PCA(n_components=i+1)\n",
    "    principalComponents = pca.fit_transform(std_X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "    # Creating the SVM model and fitting it\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y, train_size = 0.80, test_size = 0.20, random_state=0)\n",
    "    model = SVR(kernel='linear', C=1e3) \n",
    "    model.fit(X_train, Y_train) \n",
    "    # Creating predictions with the test data\n",
    "    Y_lin = model.predict(X_test)\n",
    "\n",
    "    mean_squared_error.append(metrics.mean_squared_error(Y_test, Y_lin))\n",
    "\n",
    "# Plotting the mean squared error against the iterations\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.figure()\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.plot(range(11), mean_squared_error, label = 'Mean Squared Error', color = 'blue')\n",
    "plt.xlabel('Iterations', color = 'blue')\n",
    "plt.ylabel('Mean Squared Error', color = 'blue')\n",
    "plt.title('Figure 4: Mean Squared Error vs the Iterations for Linear Kernel')\n",
    "plt.xticks(range(11))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82474788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a poly kernal\n",
    "mean_squared_error = []\n",
    "for i in range(11):\n",
    "    pca = PCA(n_components=i+1)\n",
    "    principalComponents = pca.fit_transform(std_X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "    # Creating the SVM model and fitting it\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y, train_size = 0.80, test_size = 0.20, random_state=0)\n",
    "    model = SVR(kernel='poly', C=1e3, degree=2) \n",
    "    model.fit(X_train, Y_train) \n",
    "    # Creating predictions with the test data\n",
    "    Y_poly = model.predict(X_test)\n",
    "\n",
    "    mean_squared_error.append(metrics.mean_squared_error(Y_test, Y_poly))\n",
    "\n",
    "# Plotting the mean squared error against the iterations\n",
    "plt.figure()\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.plot(range(11), mean_squared_error, label = 'Mean Squared Error', color = 'red')\n",
    "plt.xlabel('Iterations', color = 'red')\n",
    "plt.ylabel('Mean Squeared Error', color = 'red')\n",
    "plt.title('Figure 5: Mean Squared Error vs the Iterations for poly Kernel')\n",
    "plt.xticks(range(11))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an rbf kernal\n",
    "mean_squared_error = []\n",
    "for i in range(11):\n",
    "    pca = PCA(n_components=i+1)\n",
    "    principalComponents = pca.fit_transform(std_X)\n",
    "    principalDf = pd.DataFrame(data = principalComponents)\n",
    "\n",
    "    # Creating the SVM model and fitting it\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y, train_size = 0.80, test_size = 0.20, random_state=0)\n",
    "    model = SVR(kernel='rbf', C=1e3, gamma=0.1) \n",
    "    model.fit(X_train, Y_train) \n",
    "    # Creating predictions with the test data\n",
    "    Y_rbf = model.predict(X_test)\n",
    "\n",
    "    mean_squared_error.append(metrics.mean_squared_error(Y_test, Y_rbf))\n",
    "\n",
    "# Plotting the mean squared error against the iterations\n",
    "plt.figure()\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.plot(range(11), mean_squared_error, label = 'Mean Squared Error', color = 'green')\n",
    "plt.xlabel('Iterations', color = 'green')\n",
    "plt.ylabel('Mean Squared Error', color = 'green')\n",
    "plt.title('Figure 6: Mean Squared Error vs the Iterations for RBF Kernel')\n",
    "plt.xticks(range(11))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419c382",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the regression models for SVR\n",
    "pca = PCA(n_components=1)\n",
    "principalComponents = pca.fit_transform(X)\n",
    "X = pd.DataFrame(data = principalComponents)\n",
    "X = X.to_numpy()\n",
    "\n",
    "# Creating the SVM model and fitting it\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y, train_size = 0.80, test_size = 0.20, random_state=0)\n",
    "model = SVR(kernel='linear', C=1e3) \n",
    "model.fit(X, Y) \n",
    "Y_lin = model.predict(X)\n",
    "\n",
    "model = SVR(kernel='poly', C=1e3, degree=2)\n",
    "model.fit(X, Y) \n",
    "Y_poly = model.predict(X)\n",
    "\n",
    "model = SVR(kernel='rbf', C=1e3, gamma=0.1) \n",
    "model.fit(X, Y)\n",
    "Y_rbf = model.predict(X)\n",
    "\n",
    "lw = 2\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "plt.figure()\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "plt.scatter(X, Y, color='darkorange', label='data')\n",
    "plt.plot(X, Y_rbf, color='green', lw=lw, label='RBF model')\n",
    "plt.plot(X, Y_lin, color='blue', lw=lw, label='Linear model')\n",
    "plt.plot(X, Y_poly, color='red', lw=lw, label='Polynomial model') \n",
    "plt.xlabel('data')\n",
    "plt.ylabel('target')\n",
    "plt.title('Figure 7: Support Vector Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
