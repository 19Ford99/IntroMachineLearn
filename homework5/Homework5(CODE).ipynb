{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1131ed2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8392196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Problem 1 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b79e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "\n",
    "# Conversion to Tensor\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "w = torch.ones(())\n",
    "w1 = torch.ones(())\n",
    "w2 = torch.ones(())\n",
    "b = torch.zeros(())\n",
    "\n",
    "# Normalizing\n",
    "t_un = 0.1 * t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defintion for Model\n",
    "def model(t_u, w2, w1, b):\n",
    "    return w2 * t_u ** 2 + w1 * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24751a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for Loss\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w1, w2, b = params\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed48264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.1\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.SGD([params], lr = learning_rate)\n",
    "\n",
    "training_loop(n_epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7071846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.01\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD([params], lr = learning_rate)\n",
    "\n",
    "training_loop(n_epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb585b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Learning Rate = 0.001\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.SGD([params], lr = learning_rate)\n",
    "\n",
    "training_loop(n_epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.0001\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.SGD([params], lr = learning_rate)\n",
    "\n",
    "nonL_params = training_loop(n_epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_linear(t_u, w, b):\n",
    "    return w* t_u+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da59ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_linear(t_p, t_c):\n",
    "    squared_diffs = (2 * (t_p - t_c)) / t_p.size(0)\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_linear(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w, b = params\n",
    "        t_p = model_linear(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.0001\n",
    "params = torch.tensor([1.0, 0.0], requires_grad = True)\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD([params], lr = learning_rate)\n",
    "\n",
    "lin_params = training_loop_linear(n_epochs = 5000, optimizer = optimizer, params = params, t_u = t_un, t_c = t_c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a9915",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t_p = model(t_un, *nonL_params)\n",
    "lin_t_p = model_linear(t_un, *lin_params)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.rcParams.update({'axes.facecolor':'lightyellow'})\n",
    "fig = plt.figure(dpi=600)\n",
    "plt.xlabel('Temperature (°Fahrenheit)', color ='red')\n",
    "plt.ylabel('Temperature (°Celsius)', color ='red')\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy(), label='non-linear model')\n",
    "plt.plot(t_u.numpy(), lin_t_p.detach().numpy(), label='linear model')\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o', label = 'true data points')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68be2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Problem 2 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Defintion for Model\n",
    "def model(x5, x4, x3, x2, x1, w5, w4, w3, w2, w1, b):\n",
    "    return w5*x5 + w4*x4 + w3*x3 + w2*x2 + w1*x1 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae189847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for Loss\n",
    "def loss_fn(prices_p, prices):\n",
    "    squared_diffs = (prices_p - prices) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6199de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, learning_rate, params, input_vars, prices):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        prices_p = model(*input_vars, *params)\n",
    "        loss = loss_fn(prices_p, prices)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "        if (epoch % 500 == 0):\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a331586",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5000\n",
    "# CSV File\n",
    "housing = pd.DataFrame(pd.read_csv('Housing.csv'))\n",
    "# Splitting Data\n",
    "num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
    "prices = housing['price']\n",
    "input_vars = []\n",
    "for col in num_vars:\n",
    "     # Packing the tensor into a list to pass as a param\n",
    "    tensor = torch.tensor(housing[col]).float()\n",
    "    mean = torch.mean(tensor)\n",
    "    std = torch.std(tensor)\n",
    "    input_vars.append((tensor - mean) / std)\n",
    "prices = torch.tensor(prices.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afba930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.1\n",
    "LEARNING_RATE = 0.1\n",
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "params_new = training_loop(NUM_EPOCHS, LEARNING_RATE, params, input_vars, prices);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa50b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.01\n",
    "LEARNING_RATE = 0.01\n",
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "training_loop(NUM_EPOCHS, LEARNING_RATE, params, input_vars, prices);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.001\n",
    "LEARNING_RATE = 0.001\n",
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "training_loop(NUM_EPOCHS, LEARNING_RATE, params, input_vars, prices);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d18ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate = 0.0001\n",
    "LEARNING_RATE = 0.0001\n",
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "training_loop(NUM_EPOCHS, LEARNING_RATE, params, input_vars, prices);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Price\n",
    "prices_p = model(*input_vars, *params_new)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.xlabel('Houses Number', color = 'red')\n",
    "plt.ylabel('House Price', color = 'red')\n",
    "plt.plot(prices_p.detach().numpy(),'o', label='Predicted')\n",
    "plt.plot(prices.numpy(), 'o', label = 'True Price')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb90d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Problem 3 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ee59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV File\n",
    "housing = pd.read_csv('Housing.csv')\n",
    "num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking', 'price']\n",
    "data = housing[num_vars]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eab6b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization Scaling\n",
    "scaled = StandardScaler()\n",
    "scaled_data_raw = scaled.fit_transform(data.values[:,:])\n",
    "scaled_data = pd.DataFrame(scaled_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24976bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = torch.tensor(scaled_data.values[:,0:5], dtype=torch.float32)\n",
    "Y_data = torch.tensor(scaled_data.values[:,5], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9787a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "n_samples = X_data.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "X_train = X_data[train_indices]\n",
    "Y_train_raw = Y_data[train_indices]\n",
    "Y_train = torch.reshape(Y_train_raw, (436,1))\n",
    "\n",
    "X_val = X_data[val_indices]\n",
    "Y_val_raw = Y_data[val_indices]\n",
    "Y_val = torch.reshape(Y_val_raw, (109,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, X_train, X_val, Y_train, Y_val, epochs, train_loss, val_loss):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(X_train)\n",
    "        loss_train = loss_fn(t_p_train, Y_train)\n",
    "        t_p_val = model(X_val)\n",
    "        loss_val = loss_fn(t_p_val, Y_val)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        epochs.append(epoch)\n",
    "        train_loss.append(loss_train.item())\n",
    "        val_loss.append(loss_val.item())\n",
    "        if (epoch % 50 == 0):\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"f\" Validation loss {loss_val.item():.4f}\")\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A\n",
    "from collections import OrderedDict\n",
    "seq_model_one = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.ReLU()),\n",
    "    ('output_linear', nn.Linear(8, 1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ca9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in seq_model_one.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hidden layer.\n",
    "start_time = time.time()\n",
    "optimizer = optim.SGD(seq_model_one.parameters(), lr=0.01)\n",
    "one_epochs = []\n",
    "one_train_loss = []\n",
    "one_val_loss = []\n",
    "params_one = training_loop(n_epochs = 200, optimizer = optimizer,\n",
    "                           model = seq_model_one, loss_fn = loss_fn,\n",
    "                           X_train = X_train, X_val = X_val, Y_train = Y_train,\n",
    "                           Y_val = Y_val, epochs = one_epochs, train_loss = one_train_loss,\n",
    "                           val_loss = one_val_loss)\n",
    "end_time = time.time()\n",
    "print(f\"Training Time: {(end_time - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3bebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B\n",
    "from collections import OrderedDict\n",
    "seq_model_three = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, 8)),\n",
    "    ('hidden_activation_1', nn.ReLU()),\n",
    "    ('hidden_linear_2', nn.Linear(8, 8)),\n",
    "    ('hidden_activation_2', nn.ReLU()),\n",
    "    ('hidden_linear_3', nn.Linear(8, 8)),\n",
    "    ('hidden_activation_3', nn.ReLU()),\n",
    "    ('output_linear', nn.Linear(8, 1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8de9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in seq_model_three.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f12498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two More Additional Hidden layers (Total = 3 Hidden Layers)\n",
    "start_time = time.time()\n",
    "optimizer = optim.SGD(seq_model_three.parameters(), lr=0.01)\n",
    "three_epochs = []\n",
    "three_train_loss = []\n",
    "three_val_loss = []\n",
    "params_three = training_loop(n_epochs = 200, optimizer = optimizer,\n",
    "                             model = seq_model_three, loss_fn = loss_fn,\n",
    "                             X_train = X_train, X_val = X_val, Y_train = Y_train,\n",
    "                             Y_val = Y_val, epochs = three_epochs, train_loss = three_train_loss, \n",
    "                             val_loss = three_val_loss)\n",
    "end_time = time.time()\n",
    "print(f\"Training Time: {(end_time - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793dcf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(one_epochs, one_train_loss, label = 'Training Loss')\n",
    "plt.plot(one_epochs, one_val_loss, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs', color = 'red')\n",
    "plt.ylabel('Loss', color = 'red')\n",
    "plt.title('One Hidden Layer', color = 'red')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb7de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(three_epochs, three_train_loss, label = 'Training Loss')\n",
    "plt.plot(three_epochs, three_val_loss, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs', color = 'red')\n",
    "plt.ylabel('Loss', color = 'red')\n",
    "plt.title('Three Hidden Layers', color = 'red')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c06115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "macs, params = get_model_complexity_info(seq_model_one, (436, 5), as_strings=True,\n",
    " print_per_layer_stat=False, verbose=False)\n",
    "print(\"Problem 3 Part A\")\n",
    "print(\"Model size: \" + params)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "macs, params = get_model_complexity_info(seq_model_three, (436, 5), as_strings=True,\n",
    " print_per_layer_stat=False, verbose=False)\n",
    "print(\"Problem 3 Part B\")\n",
    "print(\"Model size: \" + params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
